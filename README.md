# ğŸ“š RAG Chatbot using LangGraph, LangChain & Groq

A **Retrieval-Augmented Generation (RAG)** based chatbot built with **LangGraph** and **LangChain**, using **Groq LLMs** for fast inference.  
The chatbot answers user queries **only from provided documents** (PDF / CSV), ensuring accurate and grounded responses.

---

## ğŸš€ Features

- ğŸ“„ Load documents (PDF / CSV)
- âœ‚ï¸ Chunk & embed documents using HuggingFace embeddings
- ğŸ§  Store embeddings in **Chroma Vector Database**
- ğŸ” Retrieve relevant context based on user query
- ğŸ¤– Generate responses using **Groq LLM**
- ğŸ•¸ï¸ Built with **LangGraph** for structured agent flow
- âŒ No hallucination â€“ answers strictly from document data

---

## ğŸ—ï¸ Tech Stack

| Layer | Technology |
|-----|-----------|
| LLM | Groq (LLaMA 3.1) |
| Agent Framework | LangGraph |
| Orchestration | LangChain |
| Embeddings | HuggingFace |
| Vector DB | Chroma |
| Language | Python |
| Environment | Python Virtual Environment |

---

## ğŸ“‚ Project Structure


RAGChat/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample.pdf
â”‚   â”œâ”€â”€ data.csv
â”‚
â”œâ”€â”€ rag_agent/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ tools.py
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ chroma_db/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository

git clone https://github.com/your-username/rag-chatbot-langgraph.git
cd rag-chatbot-langgraph
2ï¸âƒ£ Create & activate virtual environment
python -m venv .venv
windows:
.venv\Scripts\activate
3ï¸âƒ£ Install dependencies
req.txt for the python things and the 
frontend dependecies 
npm i axios
npm i create vite@latest
(react)
backend dependecies

npm i express ,nodemon ,dotenv

4ï¸âƒ£ Environment Variables

Create a .env file:
GROQ_API_KEY=your_groq_api_key_here
ğŸ§  How It Works (RAG Flow)

ğŸ“„ Load documents (PDF / CSV)

âœ‚ï¸ Split documents into chunks

ğŸ”¢ Convert chunks into embeddings

ğŸ—„ï¸ Store embeddings in Chroma DB

ğŸ” Retrieve relevant chunks for user query

ğŸ¤– Pass context + question to Groq LLM

âœ… Generate accurate answer from documents only

ğŸ§ª Example Query:
User: What is the climate of Chennai?
Bot: Chennai has an average temperature of 28.5Â°C with high humidity
and moderate rainfall, based on the provided dataset.
ğŸ§© Key Concepts Used

Retrieval-Augmented Generation (RAG)

Vector Similarity Search

LangGraph Nodes & Edges

Tool-based Retrieval

Stateless Chat (for now)

---

### ğŸ”¥ Want next?
If you want, I can:
- ğŸ”¹ Rewrite this README **for recruiters**
- ğŸ”¹ Add **architecture diagram (ASCII or image)**
- ğŸ”¹ Make a **frontend + backend README**
- ğŸ”¹ Create a **memory-enabled RAG README**
- ğŸ”¹ Optimize it for **internship/job shortlisting**

Just tell me ğŸ‘
